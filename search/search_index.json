{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hi there \ud83d\udc4b Welcome to my page","text":"<p>\ud83c\udf31 I'm a Technical Writer and Content Strategist specializing in creating content to elevate brands in the B2B and SaaS space. \ud83d\udcab I'm also a growing developer, exploring technologies like AI, Python, and Linux.  \ud83d\udd2d I'm currently learning on AI Agents and Agentic AI   \u270d\ufe0f And I frequently write on tech concepts on:</p> <p> </p>"},{"location":"#how-to-reach-me","title":"\ud83d\udceb How to reach me:","text":"<p>If you need help crafting documentation, user guide, technical tutorials or marketing prose, you can get in touch with me through:</p> <p> </p>"},{"location":"#tech-stack","title":"\ud83d\udcbb Tech Stack:","text":"<p>To get an overview of my current capabilities, here's an overview of the technologies I have explored:</p> <p> </p>"},{"location":"#github-stats","title":"\ud83d\udcca GitHub Stats:","text":"<p>Here are my GitHub stats showing the technologies I'm currently working on:</p> <p></p>"},{"location":"about/","title":"About","text":""},{"location":"knowledge_base/overview/","title":"Start here","text":"<p>Simple repository of tech concepts written in Markdown.</p> <p>Documenting my learning on different technology concepts that I'm passionate about including:</p> <ul> <li>Artificial Intelligence</li> <li>Python Programming</li> <li>Networking</li> <li>Linux</li> <li>CI/CD</li> <li>Cybersecurity</li> </ul>"},{"location":"knowledge_base/AI/llmops/AIagents/","title":"Agent Fundamentals","text":""},{"location":"knowledge_base/AI/llmops/AIagents/#available-large-language-models","title":"Available Large Language Models","text":"<ul> <li>Claude</li> <li>Gemini</li> <li>Mistral</li> <li>Anthropic </li> <li>Deepmind</li> <li>OpenAI</li> <li>Deepseek</li> <li>Cohere</li> <li>xAI</li> <li>Perplexity</li> <li>Grok</li> </ul>"},{"location":"knowledge_base/AI/llmops/AIagents/#running-models-locally-with-ollama","title":"Running Models Locally with Ollama","text":"<p>Here are some steps to follow:</p> <ol> <li> <p>Install Ollama:</p> <p>As of the writing of this post, you can download Ollama on linux using the following command:</p> <p><code>curl -fsSL https://ollama.com/install.sh | sh</code></p> <p>Otherwise, you can download Ollama on their official site</p> </li> <li> <p>Pull a model locally:</p> <p>Proceed to ollama website and select one model you can pull locally. In my case, I chose gemma3n.</p> <p>To pull the model locally, run:</p> <p><code>ollama pull gemma3n</code></p> </li> <li> <p>Start Ollama in the background:</p> <p>On your terminal, run:</p> <p><code>ollama serve</code></p> <p>If you run into an error as shown below: </p> <p>Use the command <code>sudo lsof -i :11434</code> to identify the process ID (PID) currently using this port. If the process is <code>ollama</code>, the installation script we used above has likely started ollama service.</p> WindowsLinux <pre><code>    pip install mkdocs-material\n</code></pre> <pre><code>    source venv/bin/activate\n</code></pre> </li> <li> <p>Check out this code:</p> </li> </ol> add_numbers.py<pre><code># Function to add two numbers\ndef add_two_numbers(num1, num2):\n    return num1 + num2\n\n# Example usage\nresult = add_two_numbers(5, 3)\nprint('The sum is:', result)\n</code></pre> <p>See references</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"knowledge_base/AI/llmops/RAG/","title":"Retrieval Augmented Generation (RAG)","text":""},{"location":"knowledge_base/AI/llmops/RAG/#process-of-setting-up-a-rag-workflow","title":"Process of setting up a RAG workflow","text":"<ol> <li>Select an LLM</li> <li>Create and aggregate your knowledge base<ul> <li>Using databases or vector stores like <code>Pinecone</code>, <code>FAISS</code>, <code>ChromaDB</code></li> </ul> </li> <li>Add a retriever<ul> <li>Using tools like: <code>Elasticsearch</code> or <code>vector search</code></li> </ul> </li> <li>Connect the workflow</li> </ol>"},{"location":"knowledge_base/AI/llmops/RAG/#tools-to-use","title":"Tools to use","text":"<p><code>n8n</code> <code>langflow</code> Open source frameworks like <code>Haystack</code>, <code>LlamaIndex</code>, <code>Langchain</code></p> <p>Open weights LLM (their parameters or weights are publicly available and you can modify them without any restriction) such as <code>LLaMA series</code> or <code>Mistral 7B</code></p> <p>Open weights models don't provide access to model architecture or source code for the training pipeline. They can however be fine-tuned and adapted to specific tasks.</p>"},{"location":"knowledge_base/AI/llmops/RAG/#use-cases","title":"Use cases","text":"<p>Private document analysis workflows - such workflows don't share sensitive data with third-party AI providers.</p>"},{"location":"knowledge_base/AI/llmops/fundamentals/","title":"Large Language Model Operations (LLMOps)","text":"<p>Learn more about LLMOps and its role building AI applications.</p> Overview <p>Documenting concepts learnt from Udacity's LLMOps course</p>"},{"location":"knowledge_base/AI/llmops/fundamentals/#definition-large-language-model-llm","title":"Definition - Large Language Model (LLM)","text":"<p>An LLM is an AI system that is trained on a lot of language data (often times trillions of tokens).</p> <p>An LLM is capable of performing various language tasks including:</p> <ul> <li>Engaging in natural language conversations.</li> <li>Information extraction.</li> </ul> <p>When developing applications that leverage LLMS, you need to:</p> <ul> <li>Test, analyze and debug models</li> <li>Implement the right infrastructure</li> <li>Incorporate the best tools to maximize app performance</li> </ul> <p>Working with LLMs requires that you work with a lot of data (in the case of Fine Tuning), lots of compute and have prompt engineering expertise.</p> <p>This is where LLMOps comes in.</p> <p>LLMOps refers to the best practices, techniques and tools for operationalizing LLMs in production environment.</p> <p>With LLMOps, you can apply best practices when building, deploying and maintaining LLMs.</p>"},{"location":"knowledge_base/AI/llmops/fundamentals/#overview-of-llmops-landscape","title":"Overview of LLMOps Landscape","text":"<p> Source: Udacity</p>"},{"location":"knowledge_base/AI/llmops/fundamentals/#llmops-lifecycle","title":"LLMOps Lifecycle","text":"<p>Below is an overview of the 6 steps that form the LLMOps Lifecycle.</p> <p></p>"},{"location":"knowledge_base/AI/llmops/fundamentals/#benefits-of-llmops","title":"Benefits of LLMOps","text":"<p>LLMOps strategies help to counter some of the challenges of working with LLMs including:</p> <ul> <li>Addressing catastrophic failures through monitoring and maintenance.</li> <li>Reducing time and cost by streamlining the process of building and deploying LLMs.</li> <li>Managing, scaling and mainitaining LLMs.</li> <li>Improving performance and reliability of LLMs.</li> </ul>"},{"location":"knowledge_base/AI/llmops/fundamentals/#references","title":"References","text":"<ol> <li>LLMOps: Building Real-World Applications With Large Language Models</li> <li>What is a large language model (LLM)? - University of Arizona Libraries</li> <li>What is fine-tuning? A guide to fine-tuning LLMs</li> </ol>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/","title":"Prompt Engineering","text":"<p>Prompt Engineering refers to the practice of designing/crefting effective prompts to improve the reliability and accuracy of AI models.</p> <p>Prompts enable AI models to:</p> <ul> <li>Understand intent</li> <li>Follow instructions</li> <li>Generate desired outputs</li> </ul> <p>Additionally, Prompt Engineering helps you optimize prompts in order to control an LLMs output.</p> <p>Crafting a good prompt is the difference between a reliable and an unreliable model. But what metrics define a good prompt? </p>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#defining-prompts","title":"Defining Prompts","text":"<p>Below are a few tips on crafting concise prompts to improve AI model accuracy.</p> <p>Source: Udacity</p>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#prompting-techniques","title":"Prompting Techniques","text":""},{"location":"knowledge_base/AI/llmops/prompt_engineering/#zero-shot-prompting","title":"Zero-shot Prompting","text":""},{"location":"knowledge_base/AI/llmops/prompt_engineering/#few-shot-in-context-learning","title":"Few-shot In-context Learning","text":"<ul> <li>You give the model high-quality demonstrations to guide it.</li> </ul>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#react","title":"ReAct","text":"<ul> <li>LLMs make use of external knowldege and tools to improve output and reduce hallucination.</li> </ul>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#chain-of-thought-cot","title":"Chain-of-thought (CoT)","text":"<ul> <li>If you want the model to take time to reason.</li> </ul>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#prompt-chaining","title":"Prompt Chaining","text":"<ul> <li>Chain several prompts</li> </ul>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#tree-of-thoughts","title":"Tree of thoughts","text":""},{"location":"knowledge_base/AI/llmops/prompt_engineering/#retrieval-augmented-generation-rag","title":"Retrieval Augmented Generation (RAG)","text":"<ul> <li>Leverage external knowledge to omptimize the context of prompts</li> </ul>"},{"location":"knowledge_base/AI/llmops/prompt_engineering/#references","title":"References","text":"<ol> <li>Prompt Engineering for AI Guide | Google Cloud</li> <li>LLMOps: Building Real-World Applications With Large Language Models</li> </ol>"},{"location":"knowledge_base/Cybersec/kali_linux/","title":"Kali Linux Overview","text":""},{"location":"knowledge_base/Cybersec/kali_linux/#introduction","title":"Introduction","text":"<p>Kali Linux is a specialized distribution (distro) of the Linux operating system based on Ubuntu Linux. Ubuntu Linux is based on Debian Linux. A Linux distro is a collection of software packages selected by the distro maintainers.</p> <p>Different distros have different package managers, for instance:</p> <ul> <li>RedHat and its associated distros like Fedora Core and RedHat Enterprise Linux (RHEL) use the RedHat Package Manager (RPM) format. RedHat uses both the RPM utility and the YellowDog Updater Modified (yum).</li> <li>Debian uses the Advanced Package Tool (APT) to manage packages in the Debian package format.</li> </ul> <p>You can use Kali Linux if you are interested in:</p> <ul> <li>Exploit development</li> <li>Digital forensics</li> <li>Security testing</li> <li>Reverse engineering</li> </ul> <p>DevOps1</p> <p>DevOps2 Linux</p>"},{"location":"knowledge_base/python/OOP/","title":"OOP","text":""},{"location":"knowledge_base/python/OOP/#definitions","title":"Definitions","text":"<ul> <li>Class - blueprint for creating objects. Defines the atrributes, data, behavior, and methods that subsequent methods will have.</li> <li>Object - an instance of a class.</li> <li>Attributes - are the variables that store information about and object.</li> <li>Methods - functions defined inside a class. Define what actions or behaviors and object can perform.</li> <li><code>self</code> parameter - is the instance or specific object of the class itself. We use it to access the specific object attributes and methods from inside a class.</li> </ul>"},{"location":"knowledge_base/python/fundamentals/","title":"Python Fundamentals","text":""},{"location":"knowledge_base/python/fundamentals/#introduction","title":"Introduction","text":"<p>Python is a dynamically typed and interpreted language that supports multiple programming paradigms such as:</p> <ul> <li>Procedural programming: a programming paradigm that involves breaking down a program into small, reusable parts called procedures or functions. Used in tasks that involve repetitive operations. However, this programming paradigm lacks features like data hiding and modularity, and treats data and functions as separate entities.</li> </ul> <ul> <li>Object-oriented programming (OOP): a programming paradigm that organizes code around objects (instances of classes). Objects represent real-world entities and each object has its own state (data - stored as attributes/properties) and behavior (methods/functions). Emphasizes modularity, reusability, and encapsulation. OOP has four pillars including:<ul> <li>Inheritance: a new class (subclass) can inherit the properties and methods on an existing class (superclass). Helps with reducing duplication and enhancing code reusability through creating hierarchical relationships between classes.</li> <li>Encapsulation: Imagine a capsule (class), where you bundle the attributes (data) and methods into it, all while restricting access to an object's internal state (with controlled access using methods). Helps to create modular and secure code thus promoting data integrity.</li> <li>Polymorphism: Treat the objects of different classes as objects of a common superclass. This way, you can call methods that perform differently based on the objects they are invoked on. Helps with extensibility and flexibility of code.</li> <li>Abstraction: Hiding implementation details and exposing only the essential functionalities of a given object. Helps create a clear and high-level view of an object's behavior.</li> </ul> </li> </ul> <ul> <li>Functional programming: Declarative programming paradigm where you create programs using functions purely. Functions are treated as first-class citizens (meaning you can pass them as arguments, return them from other functions, and bind them to names including local identifiers). Functional programming allows you to write software in a declarative and composable style.</li> </ul> <p>Python is an ideal language for scripting and Rapid Application Development. You can also use Python as an extension language for any customizable apps. You can easily extend the Python interpreter with new functions and data types. That is, those that are implemented in C, C++, or even other languages callable from C.</p> <p>Python is a high-level language with high-level data types built in, such as:</p> <ul> <li>Dictionaries</li> <li>Flexible arrays</li> </ul> <p>These high-level data types gives you more leeway to express complex code as a single statement.</p> <p>Additionally, Python comes with a large collection of standard modules that provide functionalities like:</p> <ul> <li>System calls</li> <li>File I/O</li> <li>Interfaces to graphical interface toolkits i.e., Tk</li> </ul> <p>While building on top of a standard module, you can also split your programs into modules for further reuse with different Python programs.</p>"},{"location":"knowledge_base/python/fundamentals/#key-language-features","title":"Key Language Features","text":"<p>Here are some notable language features to keep in mind:</p> <ul> <li>Python is interpreted: no compilation or linking (Python handles dependencies and module imports dynamically) is necessary.</li> <li>Python is indented: you don't need opening or closing brackets like in JavaScript</li> <li>Python is extensible and usable for system-level programming: you can link a C/ C++ program and use Python as a command language or extension. This means that you end up using Python for high-level logic and C for performance-critical parts of your program.</li> </ul>"},{"location":"knowledge_base/python/fundamentals/#python-data-types","title":"Python Data Types","text":"<p>Below is a high-level overview of Python data types with examples:  Source: PYnative</p>"},{"location":"knowledge_base/python/fundamentals/#references","title":"References","text":"<ol> <li>What is Python? Executive Summary</li> <li>Rapid Application Development Model (RAD) - Software Engineering</li> <li>Extending Python with C or C++</li> <li>PYnative</li> </ol>"},{"location":"knowledge_base/python/regex/","title":"Regular Expressions","text":"<p>Notes on regular expressions in Python using the re module.</p>"},{"location":"knowledge_base/python/regex/#overview","title":"Overview","text":"<p>A regular expression (RE, regex pattern, or RegEx) is a tiny, highly specialized programming language embedded inside Python. </p> <p>Essentially, it is a pattern language for searching and matching text. RegEx basically involves defining a sequence of characters to create a search pattern. You then use this search pattern to match against a string.</p> <p>You can access RegEx through the re module.</p> <p>You can use RegEx to set rules for find a set of possible strings. You can also use RegEx to modify a string or even split it in different ways. You can search if a set of words contain:</p> <ul> <li>TeX commands</li> <li>Email addresses</li> <li>English sentences</li> </ul> <p>Note</p> <pre><code>The RegEx pattern language is small and restricted hence you can't perform all string processing tasks with it.\n</code></pre>"},{"location":"knowledge_base/python/regex/#metacharacter","title":"Metacharacter","text":"<p>Metacharacters are useful in defining RegEx search patterns. The RegEx engine interprets metacharacters in a special way and they include:</p> <p><code>. ^ * $ ? $ + [] {} () | \\</code></p> <p>Here are some RegEx metacharacters and their meaning:</p> Symbol Meaning Example <code>.</code> Match any character except new line <code>.</code> = all characters minus new line <code>[]</code> Match any one character inside <code>[abc]</code> = 'a', 'b', 'c' <code>-</code> Specifies a range inside <code>[]</code> <code>[a-z]</code> = 'a' to 'z' <code>+</code> One or more of previous <code>[0-9]+</code> = \"12\", \"4567\" <code>*</code> Zero or more occurences of the pattern <code>[a-z]*</code> = \"\", \"abc\" <code>\\d</code> Any digit (0-9) <code>\\d+</code> = \"2024\" <code>\\w</code> Any word character (a-z, A-Z, 0-9, _) <code>\\w+</code> = \"Hello123\" <code>.</code> Any character except newline <code>a.b</code> = \"acb\", \"a9b\" <code>^</code> Start of string  or when used inside a <code>[]</code> it means any character except  the ones in that set <code>^Hello</code> matches \"Hello\" <code>$</code> End of string <code>world$</code> matches \"world\""},{"location":"knowledge_base/python/regex/#regex-in-action","title":"Regex in Action","text":"<p>Now let's take a Python function and use it to search for specific set of characters using RegEx. We want to extract the first word in a string. The string can start with Meta characters like periods or commas. So we need to ignore these characters and print out the first word alone. However, the word can contain an apostrophe within it.</p> <pre><code># importing the re module\nimport re\n\n# A function to extract words based on set rules\ndef input_text(text: str) -&gt; str:\n\n    # Setting RegEx rule to find any sequence of letters (a-z, A-Z) and apostrophes (')\n    find_match = re.search(r\"[a-zA-Z']+\", text)\n\n    if find_match:\n        return find_match.group(0)\n    return \"\"\n\n\n# Let's call the function\ninput_text(\"...Let's visit... the new museum\")\n\n# Result\n\"Let's\"\n</code></pre>"}]}